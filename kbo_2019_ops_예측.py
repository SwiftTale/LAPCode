# -*- coding: utf-8 -*-
"""KBO 2019 OPS 예측.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15MiBwVDZRFLu-RJy6MTwyICLVSEQ6ew1
"""

#데이터 패키지
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
plt.style.use('fivethirtyeight') #파이브써티에잇
import warnings
warnings.filterwarnings('ignore') #워닝 무시

"""1. 데이터 불러오기"""

regular=pd.read_csv("Regular_Season_Batter.csv")

regular.head()

regular=regular.loc[~regular['OPS'].isnull(),]

submission=pd.read_csv("submission.csv")

"""컬럼 딕셔너리 만들기"""

agg={}
for i in regular.columns:
    agg[i]=[]

for i in submission['batter_name'].unique():
    for j in regular.columns:
        if j in ['batter_id','batter_name','height/weight','year_born','position','starting_salary']:
            agg[j].append(regular.loc[regular['batter_name']==i,j].iloc[0])
        elif j=='year':
            agg[j].append(2019)
        else:
            agg[j].append(0)
regular=pd.concat([regular,pd.DataFrame(agg)])

"""2. 데이터 엿보기

클래스 속성

로우 갯수 RangeIndex: 2454 entries, 0 to 2453

컬럼 갯수 Data columns (total 29 columns):

키와 몸무게 컬럼의 차이 확인 "height/weight 1652 non-null object"

특히 우리는 추후 None Numerical 인 Object 데이터 타입의 처리에 신경을 써야된다
"""

regular.info()

regular.head()

regular.columns

"""3. 간단한 EDA

OPS = OBP(출루율) + SLG(장타율) 이고 일반적으로 장타율이 출루율보다 평균적으로 높은 수치이다.
"""

corr = regular.loc[:,regular.dtypes == 'float64'].corr()
sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, cmap=sns.diverging_palette(220, 10, as_cmap=True))

corr = regular.loc[:,regular.dtypes == 'int64'].corr()
sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, cmap=sns.diverging_palette(220, 10, as_cmap=True))

"""일반적으로 avg(타율), SLG, OBP, OPS는 모두 높을수록 같이 수치가 증가하기에 우상향 그래프의 모습을 띄고 있다."""

sns.pairplot(regular.loc[:,regular.dtypes == 'float64'])

sns.pairplot(regular.loc[:,regular.dtypes == 'int64'])

sns.distplot(regular['year'])

regular['year'].describe()

sns.distplot(regular['AB'])

"""타석에 100번 이하 들어온 타자들이 많다."""

regular['AB'].describe()

sns.distplot(regular['OPS'].dropna())

"""OPS는 대략적으로 정규분포를 따른다."""

regular['OPS'].describe()

"""타석수가 많은 타자들이 OPS가 높은 경향을 보이는 데 이는 성적이 더 좋은 타자가 경기에 많이 기용되기에 보이는 그래프이다."""

plt.scatter(regular['AB'],regular['OPS'])
plt.xlabel('AB')
plt.ylabel('OPS')

"""연도별 타석수로 어느정도 일정 수치를 유지하다가 2015년도부터 10구단 체제로 144경기로 늘어났기에 타석수가 늘어난 모습을 보인다."""

plt.scatter(regular['year'],regular['AB'])
plt.xlabel('year')
plt.ylabel('AB')

regular.groupby('position')['OPS'].mean()

"""4. BABIP 신의 강림

야구에는 많은 운들이 작용한다. 먼저 좀 더 정확한 OPS를 예측하기 위해서는 운에 의한 영역들을 어느정도 배제해야 한다. 2016년도 MLB에서 김현수는 한국팬들에게 BABIP 신이라고 불렸다. 그리고 참고한 레퍼런스의 2007년도 이현곤도 마찬가지다. BABIP이란 인플레이 타구들로만 이루어진 타율이라고 생각하면 간단하다. 식은 아래 새로운 변수에 표시되어 있다.

그래서 선수들의 스탯들을 두 시즌 간의 자기상관 관계를 통해서 파악할 것이다. 자기상관 계수가 낮다면 해당 스탯은 운에 의해 많은 영향을 받는 변동성이 큰 지표라고 해석할 수 있고, 높다면, 해당 스탯은 운에 의해 영향을 비교적 덜 받는, 지표라고 해석할 수 있을 것이다.
"""

def get_self_corr(var,regular=regular):
    x=[]
    y=[]
    regular1=regular.loc[regular['AB']>=50,]
    for name in regular1['batter_name'].unique():
        a=regular1.loc[regular1['batter_name']==name,].sort_values('year')
        k=[]
        for i in a['year'].unique():
            if (a['year']==i+1).sum()==1:
                k.append(i)
        for i in k:
            x.append(a.loc[a['year']==i,var].iloc[0])
            y.append(a.loc[a['year']==i+1,var].iloc[0])
    plt.scatter(x,y)
    plt.title(var)
    plt.show()
    print(pd.Series(x).corr(pd.Series(y))**2)

regular['1B']=regular['H']-regular['2B']-regular['3B']-regular['HR']

for i in ['avg','1B','2B','3B']:
    get_self_corr(i)

"""타율, 1루타, 2루타, 3루타는 자기상관 계수가 낮은 모습을 볼 수 있고 1루타와 2루타는 어느정도는 운에 영향이 받는다고 해석할 수 있지만, 3루타는 수치가 극단적으로 낮은 경향을 보이는 데 이는 3루타의 경우에는 타구의 질도 중요하지만 추가적으로 타자의 주력이 더 중요한 부분이기에 운에 의한 발생이 현저히 적다고 해석할 수 있다."""

for i in ['HR','BB']:
    get_self_corr(i)

"""홈런과 볼넷은 자기상관 계수가 높아 운보다는 실력이 더 중요하다고 판단 할 수 있지만 극단적으로 높지 않은 것은 타자 역시 두 시즌 연속으로 일정한 스탯을 유지하는 것은 매우 힘들기 때문이다.

아래는 BABIP의 공식이다. 타율 공식에 자기상관 계수가 높은 홈런을 빼고, 타수이기에 볼넷은 이미 빠진 수치이기에 포함되지 않는다. 그리고 인플레이 타구로만 정확히 측정하기 위해 삼진까지 빼면 BABIP의 공식이 되는 것이다.

사실 레퍼런스의 공식들을 더한 공식이 BABIP의 공식이 되는 것이다. 

투수와 타자 모두 선수의 BABIP은 달라지지 않고 수렴한다는 것이 중론이다. 통산 BABIP에 비해서 BABIP이 높은 시즌은 운이 좋은 시즌이며, 낮으면 운이 나쁜 시즌이라고 불리는 것이다.
"""

regular['avg_luck']=(regular['H']-regular['HR'])/(regular['AB']-regular['HR']-regular['SO'])

for j in ['avg', 'G', 'AB', 'R', 'H','2B', '3B', 'HR', 'TB', 'RBI', 'SB', 'CS', 'BB', 'HBP', 'SO', 'GDP','SLG', 'OBP', 'E','avg_luck']:
    lag_1_avg=[]
    for i in range(len(regular)): 
        if len(regular.loc[(regular['batter_name']==regular['batter_name'].iloc[i])&(regular['year']==regular['year'].iloc[i]-1)][j])==0:
            lag_1_avg.append(np.nan)
        else:
            lag_1_avg.append(regular.loc[(regular['batter_name']==regular['batter_name'].iloc[i])&(regular['year']==regular['year'].iloc[i]-1)][j].iloc[0])
    
    regular['lag_1_'+j]=lag_1_avg
    print(j)

"""N-1 년까지의 누적값 저장하기"""

def get_nujuk(name,year,var):
    if (len(regular.loc[(regular['batter_name']==name)&(regular['year']<year-1),'H'])!=0):
        return regular.loc[(regular['batter_name']==name)&(regular['year']<year-1),var].sum()
    else:
        return np.nan

for i in ['G', 'AB', 'R', 'H','2B', '3B', 'HR', 'TB', 'RBI', 'SB', 'CS', 'BB', 'HBP', 'SO']:
    regular['total_'+i]=regular.apply(lambda x: get_nujuk(x['batter_name'],x['year'],i),axis=1)

from sklearn.ensemble import RandomForestRegressor

"""train 데이터는 2017년까지의 성적, test 데이터는 2018년도의 성적으로 분류한다."""

train=regular.loc[regular['year']<=2017,]
test=regular.loc[regular['year']==2018,]
y_train=train['OPS']
X_train=train[[x for x in regular.columns if ('lag' in x)|('total' in x)]]

y_test=test['OPS']
X_test=test[[x for x in regular.columns if ('lag' in x)|('total' in x)]]

# X_train에 무한대 또는 float32 자료형의 범위를 벗어나는 값이 있는지 확인
print(np.isinf(X_train).sum())
print(np.isinf(y_train).sum())
print(np.isnan(X_train).sum())
print(np.isnan(y_train).sum())
print(np.nanmax(X_train))
print(np.nanmax(y_train))

#로지스틱 회귀 분석
rf=RandomForestRegressor(n_estimators=500)
rf.fit(X_train.fillna(-1),y_train,sample_weight=train['AB'])

pred=rf.predict(X_test.fillna(-1))

#MSE값 구하기
real=test['OPS']
ab=test['AB']

from sklearn.metrics import mean_squared_error
mean_squared_error(real,pred,sample_weight=ab)**0.5

"""2019년 OPS 예측 학습"""

train=regular.loc[regular['year']<=2018,]
test=regular.loc[regular['year']==2019,]
y_train=train['OPS']
X_train=train[[x for x in regular.columns if ('lag' in x)|('total' in x)]]


rf=RandomForestRegressor(n_estimators=500)
rf.fit(X_train.fillna(-1),y_train,sample_weight=train['AB'])

test=regular.loc[regular['year']==2019,]

pred=rf.predict(test[[x for x in regular.columns if ('lag' in x)|('total' in x)]].fillna(-1))

#저장
pd.DataFrame({'batter_name':test['batter_name'],'OPS':pred}).to_csv("baseline_submission.csv",index=False)

