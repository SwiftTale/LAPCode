# -*- coding: utf-8 -*-
"""Boston Housing Price.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dFPdjBu1PSciCwrMXEVO6LzvGqkpAuB1
"""

# 데이터 전처리 패키지
import numpy as np
import pandas as pd

# 데이터 시각화 패키지
import matplotlib.pyplot as plt 
import seaborn as sns 

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.linear_model import SGDRegressor

# 머신러닝 패키지
import tensorflow as tf 
from keras import layers 

# 데이터셋 불러오기
data = pd.read_csv('1958881A4B17C8519E.csv')

# Train set : Test set 비율 7:3
train_data = data.sample(frac=0.7, random_state=42)
test_data = data.drop(train_data.index)

# Import한 데이터 구조(레코드 수, 변수 수) 출력
print("Shape of data: ", data.shape)

# Train, Test set의 레코드 수 출력
print("Number of records in train set: ", len(train_data))
print("Number of records in test set: ", len(test_data))

# 데이터 시각화
sns.pairplot(data)
plt.show()

# DNN 모델과 최적화 방법을 정의하는 함수
def build_and_compile_model(norm):
  model = tf.keras.Sequential([
      norm,
      layers.Dense(64, activation='relu'),
      layers.Dense(64, activation='relu'),
      layers.Dense(1)
  ])

  model.compile(loss='mean_squared_error',
                optimizer=tf.keras.optimizers.Adam(0.001))
  return model

# train set의 변수와 목표 변수 선택
x_train = train_data.drop('MEDV', axis=1)
y_train = train_data['MEDV'] 

input_layer = tf.keras.layers.Normalization() 
input_layer.adapt(np.array(x_train))   

# 정의된 함수를 호출하여 DNN모델 빌드
dnn_model = build_and_compile_model(input_layer)

# 모델 구조 확인
dnn_model.summary()

# Commented out IPython magic to ensure Python compatibility.
# %%time 
# # 200 epoch에 대한 훈련을 실행하고 진행 과정 기록
# history = dnn_model.fit(
#     x_train,
#     y_train,
#     validation_split=0.2,
#     epochs=100)

# 훈련과정을 시각화하기 위한 함수 정의
def plot_loss(history):
  plt.plot(history.history['loss'], label='loss')
  plt.plot(history.history['val_loss'], label='val_loss') 
  plt.xlabel('Epoch')
  plt.ylabel('Error [MSE]')
  plt.ylim([0, 50])
  plt.legend()
  plt.grid(True)

# 훈련과정 시각화
plot_loss(history)

# Test set 평가
x_test = test_data.drop('MEDV', axis=1)
y_test = test_data['MEDV']

# 테스트 결과 수집
test_results = {}
test_results['dnn_model'] = dnn_model.evaluate(x_test, y_test)

from sklearn.metrics import mean_squared_error

# 테스트 데이터에 대한 예측 수행
test_predictions = dnn_model.predict(x_test).flatten()

# 예측 결과 시각화 및 MSE 계산
mse = mean_squared_error(y_test, test_predictions)
plt.scatter(y_test, test_predictions)
plt.xlabel('True Values [MSE]')
plt.ylabel('Predictions [MSE]')
lims = [0, 50]
plt.xlim(lims)
plt.ylim(lims)
_ = plt.plot(lims, lims)
plt.text(10, 40, f'MSE={mse:.2f}')